Here are **chapter-wise short notes** generated from your file **â€œ08-Sale Day Jitters.mdâ€** â€” clear, crisp, and ready for revision ğŸ‘‡

---

### ğŸ•’ 00:00 â€“ Traffic Estimation

* Flash sale expected to create heavy, short-term spikes.
* Estimate load â†’ talk to founder (followers, email users, ad impressions).
* Assume ~10Ã— daily sales; plan accordingly.
* Decide capacity increase (3Ã—â€“10Ã—) balancing **cost vs performance**.
* Remember â†’ even big companies mis-predict traffic.

---

### âš™ï¸ 02:26 â€“ Scaling Strategy

* **Pre-emptive scaling:** add more servers before sale.
* **Monitor metrics:** latency, memory, CPU â†’ add servers dynamically.
* **Analyze access patterns:**

  * Cache common reads (e.g., product list).
  * Use CDN to serve static + semi-static data.
* **Three-step approach:**

  1. Estimate load.
  2. Pre-scale infra.
  3. Cache & optimize critical paths.
* **Load testing:** find how many requests one server can handle within SLA.

---

### ğŸ’¥ 04:57 â€“ Sale Day!

* Unexpected 1 million concurrent users â†’ system crash.
* Queues overflow, requests retry â†’ worse overload.
* Flash sale fails â†’ logs analyzed to find abnormal traffic.

---

### ğŸ” 07:16 â€“ Finding the Root Cause

* Identify bot traffic â€“ multiple identical user IDs, rapid fire requests.
* Itâ€™s a **DDoS attack** (distributed denial of service).
* Must protect system from malicious actors before retrying the sale.

---

### ğŸ”’ 08:27 â€“ DDOS Prevention

* Use **firewalls / WAFs** (Cloudflare / AWS WAF).
* Two layers:

  1. **CDN level** â€“ block bots from fetching pages.
  2. **Server gateway** â€“ inspect & filter incoming requests.
* **Graceful degradation:**

  * Prioritize critical requests (payments, orders).
  * Deprioritize or reject less important ones.
* **Short-circuiting:** fail early instead of overloading downstream.
* **Back-pressure:** downstream drops new requests to recover.
* Systems recover faster & remain partially functional.

---

### ğŸš§ 15:32 â€“ Head of Line Blocking

* FIFO queues â†’ one slow request blocks all others.
* **Solutions:**

  * **Parallelism:** multiple queues / servers.
  * **Concurrency:** threads share CPU â†’ others progress while one waits.
  * **Better protocols:** e.g., gRPC allows out-of-order handling.
* Outcome â†’ reduced latency & smoother throughput.

---

### ğŸ›ï¸ 18:18 â€“ Another Sale!

* Sale retry â†’ success after applying fixes:

  * WAF + CDN protection.
  * Graceful degradation & short-circuit logic.
  * Concurrency + gRPC to remove head-of-line blocking.
  * Proper scaling & caching.
* System stable â†’ team & founder happy.

---

### ğŸš¦ 19:08 â€“ Rate Limiting

* Goal â†’ serve some users well vs none at all.
* Drop excess requests when capacity is full.
* **Token Bucket Algorithm:**

  * Maintain a fixed number of â€œtokens.â€
  * Each processed request consumes a token; replenished as requests finish.
  * Ensures max N parallel requests.
* **Leaky Bucket Algorithm:**

  * Requests allowed at a constant rate (time-based).
  * Useful for steady flow, but slower for bursts.
* Rate limiting typically implemented per server or distributed via cache.


